{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Salutation</th>\n",
       "      <th>Ticket_Lett</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Cabin_Lett</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex        Age  SibSp  Parch     Fare  Embarked  Salutation  \\\n",
       "0       3    0  22.000000      1      0   7.2500       0.0         1.0   \n",
       "1       1    1  38.000000      1      0  71.2833       1.0         3.0   \n",
       "2       3    1  26.000000      0      0   7.9250       0.0         2.0   \n",
       "3       1    1  35.000000      1      0  53.1000       0.0         3.0   \n",
       "4       3    0  35.000000      0      0   8.0500       0.0         1.0   \n",
       "5       3    0  29.699118      0      0   8.4583       2.0         1.0   \n",
       "6       1    0  54.000000      0      0  51.8625       0.0         1.0   \n",
       "7       3    0   2.000000      3      1  21.0750       0.0         4.0   \n",
       "8       3    1  27.000000      0      2  11.1333       0.0         3.0   \n",
       "9       2    1  14.000000      1      0  30.0708       1.0         3.0   \n",
       "\n",
       "   Ticket_Lett  Ticket_Len  Cabin_Lett  FamilySize  IsAlone  \n",
       "0            3           9           0           2        0  \n",
       "1            0           8           1           2        0  \n",
       "2            3          16           0           1        1  \n",
       "3            1           6           1           2        0  \n",
       "4            3           6           0           1        1  \n",
       "5            3           6           0           1        1  \n",
       "6            1           5           2           1        1  \n",
       "7            3           6           0           5        0  \n",
       "8            3           6           0           3        0  \n",
       "9            2           6           0           2        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SET PARAMETERS\n",
    "file_model = 'train'\n",
    "file_score = 'test'\n",
    "\n",
    "# トレーニングデータをロード  \n",
    "train = pd.read_csv('./data/'+ file_model + '.csv', header=0)\n",
    "\n",
    "# Sex/ Embarked : 数値に変換\n",
    "# 欠損値は平均で補完\n",
    "train= train.replace(\"male\",0).replace(\"female\",1).replace(\"S\",0).replace(\"C\",1).replace(\"Q\",2)\n",
    "train[\"Age\"].fillna(train.Age.mean(), inplace=True)\n",
    "train[\"Embarked\"].fillna(train.Embarked.mean(), inplace=True)\n",
    "\n",
    "# Name \"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5\n",
    "# 上記敬称パターンに無い例外的な敬称はRareとする\n",
    "# 欠損は0\n",
    "combine1 = [train]\n",
    "for train in combine1: \n",
    "        train['Salutation'] = train.Name.str.extract(' ([A-Za-z]+).', expand=False) \n",
    "\n",
    "for train in combine1: \n",
    "        train['Salutation'] = train['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        train['Salutation'] = train['Salutation'].replace('Mlle', 'Miss')\n",
    "        train['Salutation'] = train['Salutation'].replace('Ms', 'Miss')\n",
    "        train['Salutation'] = train['Salutation'].replace('Mme', 'Mrs')\n",
    "        del train['Name']\n",
    "\n",
    "Salutation_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \n",
    "\n",
    "for train in combine1: \n",
    "        train['Salutation'] = train['Salutation'].map(Salutation_mapping) \n",
    "        train['Salutation'] = train['Salutation'].fillna(0)\n",
    "\n",
    "\n",
    "# Ticket \n",
    "# Ticketの先頭の文字で分類\n",
    "# 文字列の長さでも分類\n",
    "for train in combine1: \n",
    "        train['Ticket_Lett'] = train['Ticket'].apply(lambda x: str(x)[0])\n",
    "        train['Ticket_Lett'] = train['Ticket_Lett'].apply(lambda x: str(x)) \n",
    "        train['Ticket_Lett'] = np.where((train['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), train['Ticket_Lett'], np.where((train['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0')) \n",
    "        train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x)) \n",
    "        del train['Ticket'] \n",
    "\n",
    "train['Ticket_Lett']=train['Ticket_Lett'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\n",
    "\n",
    "# Cabin\n",
    "# 先頭の文字で分類\n",
    "for train in combine1: \n",
    "    train['Cabin_Lett'] = train['Cabin'].apply(lambda x: str(x)[0]) \n",
    "    train['Cabin_Lett'] = train['Cabin_Lett'].apply(lambda x: str(x)) \n",
    "    train['Cabin_Lett'] = np.where((train['Cabin_Lett']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']),train['Cabin_Lett'], np.where((train['Cabin_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0'))\n",
    "del train['Cabin'] \n",
    "train['Cabin_Lett']=train['Cabin_Lett'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\n",
    "\n",
    "# Add FamilySize/IsAlome\n",
    "# 一緒に乗船している人数によって生存に大きく差が出る為、FamilySize/isAloneを項目として追加します。\n",
    "# ここまででまだ使われていないものはPclass、SibspとParchです。\n",
    "# Pclassは何等級のところに乗っていたかを表すものなのでこのままでいいです。\n",
    "# Sibspは乗っていた夫婦と兄弟の人数を表したものです。Parchは乗っていた親と子供の人数を表したものです。\n",
    "# よってSibsp+Parch+1がFamilySizeとなります。また、FamilySizeが1だとIsAlone一人で乗っているかどうかが1となります。\n",
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "for train in combine1:\n",
    "    train['IsAlone'] = 0\n",
    "    train.loc[train['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "ID = train.iloc[:,0] \n",
    "X  = train.iloc[:, 2:] # Pclass以降の変数\n",
    "y  = train.iloc[:, 1]  # 正解データ    \n",
    "X_columns = X.columns.values\n",
    "\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId\n",
       "0          892\n",
       "1          893\n",
       "2          894\n",
       "3          895\n",
       "4          896\n",
       "5          897\n",
       "6          898\n",
       "7          899\n",
       "8          900\n",
       "9          901"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータをロード\n",
    "test = pd.read_csv('./data/'+ file_score + '.csv', header=0)\n",
    "test= test.replace(\"male\",0).replace(\"female\",1).replace(\"S\",0).replace(\"C\",1).replace(\"Q\",2)\n",
    "\n",
    "test[\"Age\"].fillna(train.Age.mean(), inplace=True)\n",
    "test[\"Fare\"].fillna(train.Fare.mean(), inplace=True)\n",
    "\n",
    "combine = [test]\n",
    "for test in combine:\n",
    "    test['Salutation'] = test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "for test in combine:\n",
    "    test['Salutation'] = test['Salutation'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "         'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    test['Salutation'] = test['Salutation'].replace('Mlle', 'Miss')\n",
    "    test['Salutation'] = test['Salutation'].replace('Ms', 'Miss')\n",
    "    test['Salutation'] = test['Salutation'].replace('Mme', 'Mrs')\n",
    "    del test['Name']\n",
    "Salutation_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for test in combine:\n",
    "    test['Salutation'] = test['Salutation'].map(Salutation_mapping)\n",
    "    test['Salutation'] = test['Salutation'].fillna(0)\n",
    "\n",
    "for test in combine:\n",
    "        test['Ticket_Lett'] = test['Ticket'].apply(lambda x: str(x)[0])\n",
    "        test['Ticket_Lett'] = test['Ticket_Lett'].apply(lambda x: str(x))\n",
    "        test['Ticket_Lett'] = np.where((test['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), test['Ticket_Lett'],\n",
    "                                   np.where((test['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            '0', '0'))\n",
    "        test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "        del test['Ticket']\n",
    "test['Ticket_Lett']=test['Ticket_Lett'].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3) \n",
    "\n",
    "for test in combine:\n",
    "        test['Cabin_Lett'] = test['Cabin'].apply(lambda x: str(x)[0])\n",
    "        test['Cabin_Lett'] = test['Cabin_Lett'].apply(lambda x: str(x))\n",
    "        test['Cabin_Lett'] = np.where((test['Cabin_Lett']).isin(['T', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A']),test['Cabin_Lett'],\n",
    "                                   np.where((test['Cabin_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            '0','0'))        \n",
    "        del test['Cabin']\n",
    "test['Cabin_Lett']=test['Cabin_Lett'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1).replace(\"G\",1) \n",
    "\n",
    "test[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "\n",
    "for test in combine:\n",
    "    test['IsAlone'] = 0\n",
    "    test.loc[test['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "IDs = test.iloc[:,[0]] \n",
    "Xs  = test.iloc[:, 1:]\n",
    "\n",
    "IDs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 25, 50, 75, 100], 'n_jobs': [4], 'min_samples_split': [5, 10, 15, 20, 25, 30], 'max_depth': [5, 10, 15, 20, 25, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パラメータチューニング\n",
    "param_grid_rf = {'n_estimators'      : [10,25,50,75,100],\n",
    "                 'n_jobs'            : [4],\n",
    "                 'min_samples_split' : [5,10,15,20,25,30],\n",
    "                 'max_depth'         : [5,10,15,20,25,30]}\n",
    "\n",
    "rf_clf = GridSearchCV(RandomForestClassifier(), param_grid_rf)\n",
    "rf_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "# pipe_knn = Pipeline([('scl',StandardScaler()), ('est',KNeighborsClassifier())])\n",
    "pipe_logistic = Pipeline([('scl', StandardScaler()), ('est',LogisticRegression())])\n",
    "pipe_rf = Pipeline([('scl',StandardScaler()),('est',rf_clf.best_estimator_)])\n",
    "pipe_gb = Pipeline([('scl',StandardScaler()),('est',GradientBoostingClassifier())])\n",
    "pipe_mlp = Pipeline([('scl',StandardScaler()),('est',MLPClassifier(max_iter=2000,hidden_layer_sizes=(4,2)))])\n",
    "# pipe_svc = Pipeline([('scl',StandardScaler()),('est',LinearSVC(random_state=1))])\n",
    "pipe_xgb = Pipeline([('scl',StandardScaler()),('est',XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Counter({0: 549, 1: 549})\n"
     ]
    }
   ],
   "source": [
    "# Process for Imbalanced data\n",
    "# 不均衡データ対応処理\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "\n",
    "# Original\n",
    "y = y.as_matrix().ravel()\n",
    "\n",
    "# データが不均衡である場合、Smoteのみ行うこととする。（全部やると時間がかかりすぎる為）\n",
    "smt = SMOTE()\n",
    "X_smt,y_smt = smt.fit_sample(X, y)\n",
    "print('SMOTE', Counter(y_smt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter one of the following metrics number\n",
      "1:accuracy, 2:precision, 3:recall, 4:f1, 5:roc_auc 5\n",
      "roc_auc\n",
      "Xgboost: 0.91870\n",
      "RandomForest: 0.91754\n",
      "GradientBoosting: 0.91505\n",
      "MLP: 0.88294\n",
      "Logistic: 0.87307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>org_train_score</th>\n",
       "      <th>org_test_score</th>\n",
       "      <th>smt_train_score</th>\n",
       "      <th>smt_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.870577</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.873072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.951800</td>\n",
       "      <td>0.885750</td>\n",
       "      <td>0.967018</td>\n",
       "      <td>0.917538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.960659</td>\n",
       "      <td>0.879868</td>\n",
       "      <td>0.969891</td>\n",
       "      <td>0.915055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.813402</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.890988</td>\n",
       "      <td>0.882942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>0.947273</td>\n",
       "      <td>0.888814</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>0.918702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          algorithm  org_train_score  org_test_score  smt_train_score  \\\n",
       "0          Logistic         0.870577        0.864198         0.881796   \n",
       "1      RandomForest         0.951800        0.885750         0.967018   \n",
       "2  GradientBoosting         0.960659        0.879868         0.969891   \n",
       "3               MLP         0.813402        0.798230         0.890988   \n",
       "4           Xgboost         0.947273        0.888814         0.962804   \n",
       "\n",
       "   smt_test_score  \n",
       "0        0.873072  \n",
       "1        0.917538  \n",
       "2        0.915055  \n",
       "3        0.882942  \n",
       "4        0.918702  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling & Scoring\n",
    "# トレーニングデータでモデルを生成し、テストデータで検証\n",
    "# cross_validateを使用\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "metrics_dict = {'1':'accuracy', '2':'precision', '3':'recall', '4':'f1', '5':'roc_auc' }\n",
    "scores_df = pd.DataFrame(index=[], columns=['algorithm','org_train_score','org_test_score','smt_train_score','smt_test_score'] )\n",
    "pipe_names = ['Logistic','RandomForest','GradientBoosting','MLP','Xgboost']\n",
    "\n",
    "pipe_scores_dict = {}\n",
    "\n",
    "print('Enter one of the following metrics number')\n",
    "input_num = input('1:accuracy, 2:precision, 3:recall, 4:f1, 5:roc_auc ')\n",
    "print(metrics_dict[input_num])\n",
    "\n",
    "\n",
    "# pipe_lines = [pipe_knn, pipe_logistic, pipe_rf, pipe_gb, pipe_mlp, pipe_svc]\n",
    "pipe_lines = [pipe_logistic, pipe_rf, pipe_gb, pipe_mlp, pipe_xgb]\n",
    "\n",
    "for (i,pipe) in enumerate(pipe_lines):\n",
    "    skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "    \n",
    "    # Train Original\n",
    "    pipe.fit(X, y)\n",
    "    joblib.dump(pipe, './model/'+ metrics_dict[input_num] + '_' +  pipe_names[i] + '_org.pkl')\n",
    "    org_scores = cross_validate(pipe, X, y, cv=skf, scoring=metrics_dict[input_num])\n",
    "    \n",
    "    # Scoring (Original)    \n",
    "    org_score = pd.DataFrame(pipe.predict(Xs), columns=['Survived'])\n",
    "    IDs.join(org_score).to_csv('./data/'+ metrics_dict[input_num] + '_' + pipe_names[i] + '_org_with_pred.csv', index=False)\n",
    "\n",
    "    # Train Smote\n",
    "    pipe.fit(X_smt, y_smt)\n",
    "    joblib.dump(pipe, './model/'+ metrics_dict[input_num] + '_' + pipe_names[i] + '_smt.pkl')\n",
    "    smt_scores = cross_validate(pipe, X_smt, y_smt, cv=skf, scoring=metrics_dict[input_num])\n",
    "    \n",
    "    # Scoring (Smote)    \n",
    "    smt_score = pd.DataFrame(pipe.predict(Xs), columns=['Survived'])\n",
    "    IDs.join(smt_score).to_csv('./data/'+ metrics_dict[input_num] + '_' + pipe_names[i] + '_smt_with_pred.csv', index=False)\n",
    "   \n",
    "    # Make Dataframe    \n",
    "    series = pd.Series([pipe_names[i],\n",
    "                        np.mean(org_scores['train_score']),\n",
    "                        np.mean(org_scores['test_score']), \n",
    "                        np.mean(smt_scores['train_score']),\n",
    "                        np.mean(smt_scores['test_score'])],\n",
    "                        index=scores_df.columns)\n",
    "    scores_df = scores_df.append(series, ignore_index = True)\n",
    "    \n",
    "    # Make scores for ranking    \n",
    "    pipe_scores_dict[pipe_names[i]] = max(np.mean(org_scores['test_score']), np.mean(smt_scores['test_score']))\n",
    "\n",
    "\n",
    "# 評価結果を性能順にソートしてprint\n",
    "for pipe, score in sorted(pipe_scores_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    print('%s: %.5f' %(pipe, score))\n",
    "    \n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
